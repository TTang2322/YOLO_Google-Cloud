{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/watopedia/github_projects/watopedia/')\n",
    "webserver_files = '/home/watopedia/Desktop/TEMP/cloud_ml_webrtc/webserver/'\n",
    "import logging\n",
    "import tornado.escape\n",
    "import tornado.ioloop\n",
    "import tornado.options\n",
    "import tornado.web\n",
    "import tornado.websocket\n",
    "import os.path\n",
    "import uuid\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "#from io import StringIO\n",
    "from io import BytesIO\n",
    "import uuid\n",
    "import numpy\n",
    "import json\n",
    "from tornado.options import define, options\n",
    "import tornado.httpserver\n",
    "import numpy as np\n",
    "import ssl\n",
    "from tornado.ioloop import PeriodicCallback\n",
    "import base64\n",
    "port = 8080\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loading Imports\n"
     ]
    }
   ],
   "source": [
    "# Add the utlities to the path\n",
    "import sys\n",
    "sys.path.append('/home/watopedia/github_projects/watopedia/')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import aipodMain.utilities.constants as constants\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Input Source Thread\n",
    "from aipodMain.threads.ImageInput.AbstractImageInputThread import AbstractImageInputThread\n",
    "\n",
    "# Predictor Threads\n",
    "from aipodMain.threads.Predictor.PredictorImage import PredictorImage\n",
    "from aipodMain.threads.Predictor.VisualizerPredictor import VisualizerPredictor\n",
    "from aipodMain.threads.Predictor.SubsetImgPredictor2 import SubsetImgPredictor\n",
    "from aipodMain.threads.Predictor.DarkNet.PredictorDarknet import DarknetYOLO\n",
    "from aipodMain.utilities.ThreadData import ThreadData\n",
    "from aipodMain.threads.Predictor.FaceRecognition.Pipeline.Wrapper import FaceDetectionRecognition as FaceNetRecog\n",
    "# GUI\n",
    "from aipodMain.GUI.draw_face_frame import draw_face_frame\n",
    "from aipodMain.GUI.draw_lidar_frame import draw_lidar_frame\n",
    "from aipodMain.GUI.draw_label_frame import draw_label_frame\n",
    "from aipodMain.GUI.draw_image_frame import draw_image_frame\n",
    "from aipodMain.GUI.MAIN_GUI import nn_draw\n",
    "# Controller\n",
    "from aipodMain.GUI.CONTROLLER import CONTROLLER\n",
    "\n",
    "# Helper Functions\n",
    "from aipodMain.utilities.ai_helper.objectcounting import objectcounting\n",
    "from aipodMain.utilities.ai_helper import helper as ai_helper\n",
    "import time\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Import ROS\n",
    "from aipodMain.utilities.other.ros.start_ros_processes import start_ros_processes\n",
    "from aipodMain.threads.ImageInput.ROSImagePublisher import ROSImagePublisher # Publish to a channel\n",
    "from aipodMain.utilities.other.ros.pointcloud_listener import LSD_SLAM_TOPIC_LISTENER\n",
    "print(\"Finished Loading Imports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRACKER\n",
    "MIN_HITS = 1 \n",
    "MAX_AGE = 4\n",
    "\n",
    "# MODEL SCORE THRESHOLD VALUES\n",
    "THRESHOLD_Y9K = 0.5\n",
    "THRESHOLD_YOLO_COCO  = 0.4\n",
    "THRESHOLD_COCO = 0.4\n",
    "THRESHOLD_INCEPTION = 0.4\n",
    "THRESHOLD_WEAPONS_ONLY = 0.6\n",
    "THRESHOLD_WEAPONS_ONLY_SUB = 0.1\n",
    "THRESHOLD_WEAPON_PARTS = 0.4\n",
    "THRESHOLD_WEAPON_PARTS_SUB = 0.4\n",
    "# Label List\n",
    "DISP_LABEL_LIST = [\n",
    "    # Weapons\n",
    "    'gun-barrel','machine-guns','trigger','handguns', 'rifle',\n",
    "    # Coco Module\n",
    "    'person', 'backpack', 'bottle', 'knife', \n",
    "    'cell phone', 'scissors', 'Weapon',\n",
    "    # Faster R-CNN Module\n",
    "    'Person','Rifle', 'Handgun', 'Shotgun', 'Digital clock', 'Alarm clock', 'Syringe',\n",
    "      \"Bottle\", \"Knife\", \"Backpack\",\n",
    "      \"Mobile phone\"]\n",
    "# Exclude All Of These Classes\n",
    "ENABLE_EXCLUDE_LABEL_LIST = True\n",
    "EXCLUDE_LABEL_LIST = [\n",
    "    # Faster R-CNN\n",
    "    'Clothing', 'Face', 'Hair', 'Head', 'Arm', 'Hand', 'Beard', 'bed','sofa',\n",
    "    # COCO\n",
    "    \"mouse\" ,\n",
    "    # Weapons\n",
    "    'NA',\n",
    "    # YOLO 9K\n",
    "    'Weapon','y9k-Rifle','y9k-Handgun','y9k-Shotgun', 'worker','creation','craftsman','living thing',\n",
    "    'instrumentality', 'artifact', 'organism', 'person-9k', 'matter', 'expert' ,'whole', 'entertainer', 'nutriment',\n",
    "    'backpack-9k', 'African','Mexican','Arabian'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class CustomImageThread(AbstractImageInputThread):\n",
    "    def __init__(self, IMAGE_WIDTH = 640 ,IMAGE_HEIGHT = 480):\n",
    "        name = 'Custom Image Thread'\n",
    "        super().__init__(name, IMAGE_WIDTH ,IMAGE_HEIGHT)\n",
    "        empty_image = np.zeros(shape=(20,20,3))\n",
    "        self.queue = deque([empty_image])\n",
    "        self.image_data.image_np = empty_image\n",
    "        self.image_data.isInit = True\n",
    "\n",
    "    def updateImg(self, threadName):\n",
    "        while not self.done:\n",
    "            last_image = self.image_data.image_np\n",
    "            try:\n",
    "                last_image = self.queue.popleft()[:,:,::-1]\n",
    "            except:\n",
    "                pass\n",
    "            self.image_data.image_np = last_image\n",
    "            time.sleep(0.05)\n",
    "            \n",
    "    def appendElement(self, image_np):\n",
    "        '''\n",
    "        Adds an image for processing to the queue.\n",
    "        '''\n",
    "        if len(self.queue) < 10:\n",
    "            self.queue.append(image_np)\n",
    "        else:\n",
    "            self.queue.popleft() # Remove the top most element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Custom Image Thread\n"
     ]
    }
   ],
   "source": [
    "objCounting = objectcounting()\n",
    "thread_image = CustomImageThread()\n",
    "thread_image.start()\n",
    "image_data = thread_image.image_data\n",
    "START_PREDICTOR = True\n",
    "thread_data = ThreadData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Predictor Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MTCNN Model\n",
      "MTCNN. Setting parameters.\n",
      "Loading Model File: /home/watopedia/github_projects/watopedia/aipodMain/nnModels/faceRecognition/faceNet/20180408-102900/20180408-102900.pb\n",
      "Finished Loading Model. Allocated 20.0% of GPU.\n",
      "FaceNetModel. Resize Image to 160x160\n",
      "Starting MTCNN Face Predictor\n",
      "Starting Face Recognition Thread.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "detector_thresh = 0.8\n",
    "recognition_thresh = 0.5\n",
    "DETECTOR_IMG_SCALE = 0.5\n",
    "TRACKER = 'Legacy'\n",
    "thread_frm = FaceNetRecog(thread_image.image_data,\n",
    "                  '/home/watopedia/github_projects/aipod-data/face_recognition/train_datasets/watopedia-2018-10-13/svm_models/facenet_mtcnn_align/classifier.pkl',\n",
    "                             detector_thresh=detector_thresh,\n",
    "                             recognition_thresh=recognition_thresh,\n",
    "                             detection_tracker=TRACKER,\n",
    "                             DETECTOR_IMG_SCALE = DETECTOR_IMG_SCALE)\n",
    "\n",
    "thread_data.addThreadElement(thread_frm,'f','FRM')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating labelmap. Saved in /home/watopedia/github_projects/watopedia/nnModels/yolov3/coco/608//label_map.pbtxt\n"
     ]
    }
   ],
   "source": [
    "thread_gsm_1 = DarknetYOLO(\"YOLO COCO\",image_data,\n",
    "                        THRESHOLD_YOLO_COCO,\n",
    "                         TRACKER_TYPE='Legacy',\n",
    "                        YOLO_DIR=\"/home/watopedia/github_projects/watopedia/nnModels/yolov3/coco/608/\",\n",
    "                          IMG_SCALE=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating labelmap. Saved in /home/watopedia/github_projects/watopedia/nnModels/yolov3/y9k//label_map.pbtxt\n",
      "Loading Model File: /home/watopedia/github_projects/aipod-data/weapons/2018-10-26/model/weapon_parts_only-vB/ssd_300/frozen/frozen_inference_graph.pb\n",
      "Finished Loading Model\n",
      "Loading Model File: /home/watopedia/github_projects/aipod-data/weapons/2018-10-26/model/weapons_only-vA/ssd_300/frozen/frozen_inference_graph.pb\n",
      "Finished Loading Model\n",
      "Tracker Disabled.\n",
      "helper_nn_models_utils. get_label_map(). Warning. No Label Map Defined\n",
      "Loading Model File: /home/watopedia/github_projects/watopedia/aipodMain/nnModels/faceRecognition/ssd_face_detector/ssd_inference_graph.pb\n",
      "Alocating 5.0% of GPU\n",
      "Finished Loading Model\n",
      "Starting Visualization Thread VISUALIZATION\n",
      "Starting YOLO COCO\n",
      "Starting YOLO 9K\n",
      "Starting weapon parts only v4\n",
      "Starting weapon only v5\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "thread_gsm_2 = DarknetYOLO(\"YOLO 9K\",image_data,\n",
    "                        THRESHOLD_YOLO_COCO,\n",
    "                         TRACKER_TYPE='Legacy',\n",
    "                        YOLO_DIR=\"/home/watopedia/github_projects/watopedia/nnModels/yolov3/y9k/\",\n",
    "                          IMG_SCALE=0.5)\n",
    "\n",
    "thread_data.addThreadElement(thread_gsm_1,'y','GSM-C',always_on=False, ignore_thread=False)\n",
    "thread_data.addThreadElement(thread_gsm_2,'u','GSM-9K',always_on=False, ignore_thread=False)\n",
    "\n",
    "\n",
    "COCO_WEAPON_PARTS_ONLY = 0.2\n",
    "v4_coco_wp = PredictorImage('weapon parts only v4',\n",
    "                       '/home/watopedia/github_projects/aipod-data/weapons/2018-10-26/model/weapon_parts_only-vB/ssd_300/frozen/frozen_inference_graph.pb',\n",
    "                       '/home/watopedia/github_projects/aipod-data/weapons/2018-10-26/model/weapon_parts_only-vB/ssd_300/label_map.pbtxt',\n",
    "                       image_data,\n",
    "                       score_thresh=COCO_WEAPON_PARTS_ONLY,\n",
    "                       TRACKER_TYPE = 'Legacy',\n",
    "                        IMG_SCALE=0.5)\n",
    "thread_data.addThreadElement(v4_coco_wp,'s','Weapon Parts Only',always_on=False, ignore_thread=False)\n",
    "\n",
    "#################################\n",
    "COCO_WEAPON_ONLY = 0.3\n",
    "v5_coco_wo = PredictorImage('weapon only v5',\n",
    "                       '/home/watopedia/github_projects/aipod-data/weapons/2018-10-26/model/weapons_only-vA/ssd_300/frozen/frozen_inference_graph.pb',\n",
    "                       '/home/watopedia/github_projects/aipod-data/weapons/2018-10-26/model/weapons_only-vA/ssd_300/label_map.pbtxt',\n",
    "                       image_data,\n",
    "                       score_thresh=COCO_WEAPON_ONLY,\n",
    "                       TRACKER_TYPE = 'Legacy',\n",
    "                           IMG_SCALE=1.0)\n",
    "thread_data.addThreadElement(v5_coco_wo,'w','Weapons Only',always_on=False, ignore_thread=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "thread_vis = VisualizerPredictor(\"Visualization Thread VISUALIZATION\",                               \n",
    "                                 constants.FACE_DETECTOR_SSD_MODEL,\n",
    "                                     image_data, MOBILE_VIS_LAYERS = True)\n",
    "\n",
    "\n",
    "thread_data.start_all()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Neural Net Layer Drawer\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "nnDraw = nn_draw(thread_vis.output_data,640,480,update_interval=5)\n",
    "t1 = threading.Thread(target=nnDraw.updateWithThread).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TORNADO DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Application(tornado.web.Application):\n",
    "    def __init__(self):\n",
    "        handlers = [\n",
    "            (r\"/\", MainHandler),\n",
    "            (r\"/test\", TestHandler),\n",
    "            (r\"/webcam\", WebcamHandler),\n",
    "            (r\"/cnn_data\", CNNHandler),\n",
    "            (r\"/mlresults\", MLResultHandler)\n",
    "            ]\n",
    "\n",
    "        settings = dict(\n",
    "            cookie_secret=\"asdsafl.rleknknfkjqweonrkbknoijsdfckjnk 234jn\",\n",
    "            template_path=os.path.join(os.path.dirname(webserver_files), \"templates\"),\n",
    "            static_path=os.path.join(os.path.dirname(webserver_files), \"static\"),\n",
    "            xsrf_cookies=False,\n",
    "            autoescape=None,\n",
    "            debug=True\n",
    "            )\n",
    "        tornado.web.Application.__init__(self, handlers, **settings)\n",
    "    def startTornado(self):\n",
    "        print(\"Starting Tornaado\")\n",
    "        http_server = tornado.httpserver.HTTPServer(app, ssl_options=ssl_ctx)\n",
    "        http_server.listen(port)\n",
    "        tornado.ioloop.IOLoop.current().start()\n",
    "    def stopTornado(self):\n",
    "        print(\"Stopping\")\n",
    "        tornado.ioloop.IOLoop.current().stop()\n",
    "\n",
    "class MainHandler(tornado.web.RequestHandler):\n",
    "    def get(self):\n",
    "        self.render(\"facedetect.html\")\n",
    "        \n",
    "class TestHandler(tornado.web.RequestHandler):\n",
    "    def get(self):\n",
    "        self.render(\"dashboard.html\")\n",
    "        \n",
    "class WebcamHandler(tornado.websocket.WebSocketHandler):\n",
    "    '''\n",
    "    When data is received, append it to our thread image queue.\n",
    "    '''\n",
    "    def open(self):\n",
    "        print('new webcam connection')\n",
    "        logging.info('new webcam connection')\n",
    "        #self.set_nodelay(True)\n",
    "        data = {}\n",
    "        data['name'] = 'empty_message'\n",
    "        self.callback = PeriodicCallback(self.update, 500)\n",
    "        self.callback.start()\n",
    "        self.empty_message = json.dumps(data)\n",
    "        self.t1 = time.time()\n",
    "\n",
    "    def on_message(self, message):\n",
    "        image = Image.open(BytesIO(message))\n",
    "        cv_image = numpy.array(image)\n",
    "        thread_image.appendElement(cv_image)\n",
    "        # Send Empty data back\n",
    "        self.write_message(self.empty_message)\n",
    "        self.t1 = time.time()  \n",
    "\n",
    "\n",
    "    def on_close(self):\n",
    "        logging.info('connection webcam closed')\n",
    "        print(\"Connection webcam closed\")\n",
    "        self.callback.stop()\n",
    "    def update(self):\n",
    "        # If we haven't heard back, send a wakeup message.\n",
    "        elapsedTime = time.time() - self.t1\n",
    "        if elapsedTime > 5:\n",
    "            self.write_message(self.empty_message)\n",
    "        \n",
    "        \n",
    "class CNNHandler(tornado.websocket.WebSocketHandler):\n",
    "    '''\n",
    "    When data is received, append it to our thread image queue.\n",
    "    '''\n",
    "    def open(self):\n",
    "        print('new ccn connection')\n",
    "        logging.info('new CNN connection')\n",
    "        self.image_np = np.ones(shape=(6,6,3))\n",
    "        self.next_message = True\n",
    "        self.t1 = time.time()\n",
    "        self.callback = PeriodicCallback(self.update, 200)\n",
    "        self.callback.start()\n",
    "\n",
    "    def on_message(self, message):\n",
    "        self.next_message = True\n",
    "    def update(self):\n",
    "        elapsedTime = time.time() - self.t1\n",
    "        if self.next_message or (elapsedTime > 2):\n",
    "            image_np = nnDraw.showNeuralNetVisualization()*255.0\n",
    "            image_np = image_np.astype('uint8')\n",
    "            data = Image.fromarray(image_np)\n",
    "            fp = BytesIO()\n",
    "            data.save(fp, 'JPEG')\n",
    "            data = base64.b64encode(fp.getvalue())\n",
    "            data = \"data:image/png;base64,\" + data.decode('utf-8')\n",
    "            self.write_message(json.dumps({\n",
    "                \"img\": data,\n",
    "                \"desc\": \"img_description\",\n",
    "            }))\n",
    "            self.next_message = False\n",
    "            self.t1 = time.time()\n",
    "        \n",
    "\n",
    "\n",
    "    def on_close(self):\n",
    "        logging.info('connection CNN closed')\n",
    "        self.callback.stop()\n",
    "        print(\"Connection CNN closed\")\n",
    "\n",
    "class MLResultHandler (tornado.websocket.WebSocketHandler):\n",
    "    '''\n",
    "    When data is received, append it to our thread image queue.\n",
    "    '''\n",
    "    def open(self):\n",
    "        logging.info('new ml result connection')\n",
    "        self.callback = PeriodicCallback(self.update, 500)\n",
    "        self.callback.start()\n",
    "        self.previous_data = []\n",
    "        self.image_height = 0\n",
    "        self.image_width = 0\n",
    "    def on_message(self, message):\n",
    "        if self.image_height == 0:\n",
    "            data = json.loads(message)\n",
    "            try:\n",
    "                self.image_height = int(data['image_properties']['height'])\n",
    "                self.image_width = int(data['image_properties']['width'])\n",
    "                print(\"received\" + \" height: \" + str(self.image_height) + \" width: \" + str(self.image_width))\n",
    "            except:\n",
    "                print(\"nope\")\n",
    "\n",
    "    def create_thread_data(self,thread_data):\n",
    "        all_data = []\n",
    "\n",
    "        for thread_ in thread_data.thread_list:\n",
    "            h = self.image_height; w = self.image_width;\n",
    "            data = {}\n",
    "            data['type'] = 'thread_data'\n",
    "            data['name'] = thread_.name\n",
    "            if 'Face' in thread_.name:\n",
    "                continue\n",
    "            data['bbs'] = self.fix_bb_coords(thread_.output_data.bbs.copy(),\n",
    "                                        h,w)\n",
    "            data['scores'] = thread_.output_data.scores.tolist()\n",
    "            class_names = []\n",
    "            for c in thread_.output_data.classes:\n",
    "                class_names.append(thread_.output_data.category_index.get(c)['name'])\n",
    "            data['classes'] = class_names\n",
    "            data['unique_labels'] = objCounting.countFromList(class_names)\n",
    "            all_data.append(data)\n",
    "        return all_data\n",
    "    def create_face_data(self,output_data):\n",
    "        data = {}\n",
    "        data['type'] = 'face_data'\n",
    "        data['db_image'] = 'omar'\n",
    "        \n",
    "    def update(self):\n",
    "        # First we need to concatenate the output data\n",
    "        all_data = self.create_thread_data(thread_data)\n",
    "\n",
    "        # Add the face data. TODO: Pass in the face data!\n",
    "        data = json.dumps(self.create_face_data(thread_frm.output_data))\n",
    "        #all_data.append(data)\n",
    "        # Prevent sending duplicate data.\n",
    "        if all_data != self.previous_data:\n",
    "            self.write_message(json.dumps(all_data))\n",
    "        self.previous_data = all_data\n",
    "\n",
    "    def fix_bb_coords(self,bbs,h,w):\n",
    "        for indx, bb in enumerate(bbs):\n",
    "            bbs[indx][0] = int(bbs[indx][0]*h)\n",
    "            bbs[indx][1] = int(bbs[indx][1]*w)\n",
    "            bbs[indx][2] = int(bbs[indx][2]*h)\n",
    "            bbs[indx][3] = int(bbs[indx][3]*w)  \n",
    "            \n",
    "            bbs[indx][0] = max(min(bbs[indx][0],h),0)\n",
    "            bbs[indx][2] = max(min(bbs[indx][2],h),0)\n",
    "            bbs[indx][1] = max(min(bbs[indx][1],w),0)\n",
    "            bbs[indx][3] = max(min(bbs[indx][3],w),0)\n",
    "                \n",
    "        return bbs.tolist()\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    def on_close(self):\n",
    "        logging.info('connection ml closed')\n",
    "        self.callback.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_gsm_1.continue_predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Application()\n",
    "ssl_ctx = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n",
    "ssl_ctx.load_cert_chain(webserver_files + \"ssl/domain.crt\",\n",
    "                       webserver_files + \"ssl/domain.key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Tornaado\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "IOLoop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ba55db2f968a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartTornado\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-b46ac8661947>\u001b[0m in \u001b[0;36mstartTornado\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mhttp_server\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtornado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttpserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPServer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mssl_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mhttp_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mtornado\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mioloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIOLoop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstopTornado\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stopping\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_running\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IOLoop is already running\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: IOLoop is already running"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n"
     ]
    }
   ],
   "source": [
    "app.startTornado()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
