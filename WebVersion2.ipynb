{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/omar_abid4_gmail_com/')\n",
    "sys.path.append('/home/omar_abid4_gmail_com/facenet/src/')\n",
    "webserver_files = '/home/omar_abid4_gmail_com/cloud_ml_webrtc/webserver/'\n",
    "nnModels = '/home/omar_abid4_gmail_com/nnModels/'\n",
    "import logging\n",
    "import tornado.escape\n",
    "import tornado.ioloop\n",
    "import tornado.options\n",
    "import tornado.web\n",
    "import tornado.websocket\n",
    "import os.path\n",
    "import uuid\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "#from io import StringIO\n",
    "from io import BytesIO\n",
    "import uuid\n",
    "import numpy\n",
    "import json\n",
    "from tornado.options import define, options\n",
    "import tornado.httpserver\n",
    "import numpy as np\n",
    "import ssl\n",
    "from tornado.ioloop import PeriodicCallback\n",
    "import base64\n",
    "port = 8888\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Loading Imports\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import aipodMain.utilities.constants as constants\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Input Source Thread\n",
    "from aipodMain.threads.ImageInput.AbstractImageInputThread import AbstractImageInputThread\n",
    "\n",
    "# Predictor Threads\n",
    "from aipodMain.threads.Predictor.PredictorImage import PredictorImage\n",
    "from aipodMain.threads.Predictor.VisualizerPredictor import VisualizerPredictor\n",
    "from aipodMain.threads.Predictor.SubsetImgPredictor2 import SubsetImgPredictor\n",
    "from aipodMain.threads.Predictor.DarkNet.PredictorDarknet import DarknetYOLO\n",
    "from aipodMain.utilities.ThreadData import ThreadData\n",
    "from aipodMain.threads.Predictor.FaceRecognition.Pipeline.Wrapper import FaceDetectionRecognition as FaceNetRecog\n",
    "# GUI\n",
    "from aipodMain.GUI.draw_face_frame import draw_face_frame\n",
    "from aipodMain.GUI.draw_lidar_frame import draw_lidar_frame\n",
    "from aipodMain.GUI.draw_label_frame import draw_label_frame\n",
    "from aipodMain.GUI.draw_image_frame import draw_image_frame\n",
    "from aipodMain.GUI.MAIN_GUI import nn_draw\n",
    "# Controller\n",
    "from aipodMain.GUI.CONTROLLER import CONTROLLER\n",
    "\n",
    "# Helper Functions\n",
    "from aipodMain.utilities.ai_helper.objectcounting import objectcounting\n",
    "from aipodMain.utilities.ai_helper import helper as ai_helper\n",
    "import time\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "print(\"Finished Loading Imports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRACKER\n",
    "MIN_HITS = 1 \n",
    "MAX_AGE = 4\n",
    "\n",
    "# MODEL SCORE THRESHOLD VALUES\n",
    "THRESHOLD_Y9K = 0.5\n",
    "THRESHOLD_YOLO_COCO  = 0.4\n",
    "THRESHOLD_COCO = 0.4\n",
    "THRESHOLD_INCEPTION = 0.4\n",
    "THRESHOLD_WEAPONS_ONLY = 0.6\n",
    "THRESHOLD_WEAPONS_ONLY_SUB = 0.1\n",
    "THRESHOLD_WEAPON_PARTS = 0.4\n",
    "THRESHOLD_WEAPON_PARTS_SUB = 0.4\n",
    "# Label List\n",
    "DISP_LABEL_LIST = [\n",
    "    # Weapons\n",
    "    'gun-barrel','machine-guns','trigger','handguns', 'rifle',\n",
    "    # Coco Module\n",
    "    'person', 'backpack', 'bottle', 'knife', \n",
    "    'cell phone', 'scissors', 'Weapon',\n",
    "    # Faster R-CNN Module\n",
    "    'Person','Rifle', 'Handgun', 'Shotgun', 'Digital clock', 'Alarm clock', 'Syringe',\n",
    "      \"Bottle\", \"Knife\", \"Backpack\",\n",
    "      \"Mobile phone\"]\n",
    "# Exclude All Of These Classes\n",
    "ENABLE_EXCLUDE_LABEL_LIST = True\n",
    "EXCLUDE_LABEL_LIST = [\n",
    "    # Faster R-CNN\n",
    "    'Clothing', 'Face', 'Hair', 'Head', 'Arm', 'Hand', 'Beard', 'bed','sofa',\n",
    "    # COCO\n",
    "    \"mouse\" ,\n",
    "    # Weapons\n",
    "    'NA',\n",
    "    # YOLO 9K\n",
    "    'Weapon','y9k-Rifle','y9k-Handgun','y9k-Shotgun', 'worker','creation','craftsman','living thing',\n",
    "    'instrumentality', 'artifact', 'organism', 'person-9k', 'matter', 'expert' ,'whole', 'entertainer', 'nutriment',\n",
    "    'backpack-9k', 'African','Mexican','Arabian'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class CustomImageThread(AbstractImageInputThread):\n",
    "    def __init__(self, IMAGE_WIDTH = 640 ,IMAGE_HEIGHT = 480):\n",
    "        name = 'Custom Image Thread'\n",
    "        super().__init__(name, IMAGE_WIDTH ,IMAGE_HEIGHT)\n",
    "        empty_image = np.zeros(shape=(20,20,3))\n",
    "        self.queue = deque([empty_image])\n",
    "        self.image_data.image_np = empty_image\n",
    "        self.image_data.isInit = True\n",
    "\n",
    "    def updateImg(self, threadName):\n",
    "        while not self.done:\n",
    "            last_image = self.image_data.image_np\n",
    "            try:\n",
    "                last_image = self.queue.popleft()[:,:,::-1]\n",
    "            except:\n",
    "                pass\n",
    "            self.image_data.image_np = last_image\n",
    "            time.sleep(0.05)\n",
    "            \n",
    "    def appendElement(self, image_np):\n",
    "        '''\n",
    "        Adds an image for processing to the queue.\n",
    "        '''\n",
    "        if len(self.queue) < 10:\n",
    "            self.queue.append(image_np)\n",
    "        else:\n",
    "            self.queue.popleft() # Remove the top most element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Custom Image Thread\n"
     ]
    }
   ],
   "source": [
    "objCounting = objectcounting()\n",
    "thread_image = CustomImageThread()\n",
    "thread_image.start()\n",
    "image_data = thread_image.image_data\n",
    "START_PREDICTOR = True\n",
    "thread_data = ThreadData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Predictor Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MTCNN Model\n",
      "MTCNN. Setting parameters.\n",
      "Loading Model File: /home/omar_abid4_gmail_com/nnModels/faceRecognition/faceNet/20180408-102900/20180408-102900.pb\n",
      "Finished Loading Model. Allocated 20.0% of GPU.\n",
      "FaceNetModel. Resize Image to 160x160\n",
      "Starting MTCNN Face Predictor\n",
      "Starting Face Recognition Thread.\n",
      "WARNING. WRONG SVM CLASSIFIER USED FOR TESTING!\n"
     ]
    }
   ],
   "source": [
    "detector_thresh = 0.8\n",
    "recognition_thresh = 0.5\n",
    "\n",
    "DETECTOR_IMG_SCALE = 0.5\n",
    "TRACKER = 'Legacy'\n",
    "thread_frm = FaceNetRecog(thread_image.image_data,\n",
    "                     nnModels + 'faceRecognition/ssd_face_detector/face_label_map.pbtxt',\n",
    "                  nnModels + 'faceRecognition/repClassifiers/custom_svm.pkl',\n",
    "                  nnModels + 'faceRecognition/faceNet/20180408-102900/20180408-102900.pb',\n",
    "                             detector_thresh=detector_thresh,\n",
    "                             recognition_thresh=recognition_thresh,\n",
    "                             detection_tracker=TRACKER,\n",
    "                             DETECTOR_IMG_SCALE = DETECTOR_IMG_SCALE)\n",
    "print(\"WARNING. WRONG SVM CLASSIFIER USED FOR TESTING!\")\n",
    "thread_data.addThreadElement(thread_frm,'f','FRM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating labelmap. Saved in /home/omar_abid4_gmail_com/nnModels/yolov3/coco/608//label_map.pbtxt\n"
     ]
    }
   ],
   "source": [
    "thread_gsm_1 = DarknetYOLO(\"YOLO COCO\",image_data,\n",
    "                        THRESHOLD_YOLO_COCO,\n",
    "                         TRACKER_TYPE='Legacy',\n",
    "                        YOLO_DIR= nnModels + \"yolov3/coco/608/\",\n",
    "                          IMG_SCALE=0.5)\n",
    "thread_data.addThreadElement(thread_gsm_1,'u','GSM-COCO',always_on=False, ignore_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracker Disabled.\n",
      "helper_nn_models_utils. get_label_map(). Warning. No Label Map Defined\n",
      "Loading Model File: /home/omar_abid4_gmail_com/nnModels/faceRecognition/ssd_face_detector/ssd_inference_graph.pb\n",
      "Alocating 5.0% of GPU\n",
      "Finished Loading Model\n",
      "Starting Visualization Thread VISUALIZATION\n",
      "Starting YOLO COCO\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "thread_vis = VisualizerPredictor(\"Visualization Thread VISUALIZATION\",   \n",
    "                                 nnModels + 'faceRecognition/ssd_face_detector/ssd_inference_graph.pb',\n",
    "                                     image_data, MOBILE_VIS_LAYERS = True)\n",
    "\n",
    "\n",
    "thread_data.start_all()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Neural Net Layer Drawer\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "nnDraw = nn_draw(thread_vis.output_data,640,480,update_interval=5)\n",
    "t1 = threading.Thread(target=nnDraw.updateWithThread).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TORNADO DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Application(tornado.web.Application):\n",
    "    def __init__(self):\n",
    "        handlers = [\n",
    "            (r\"/\", MainHandler),\n",
    "            (r\"/test\", TestHandler),\n",
    "            (r\"/webcam\", WebcamHandler),\n",
    "            (r\"/cnn_data\", CNNHandler),\n",
    "            (r\"/mlresults\", MLResultHandler)\n",
    "            ]\n",
    "\n",
    "        settings = dict(\n",
    "            cookie_secret=\"asdsafl.rleknknfkjqweonrkbknoijsdfckjnk 234jn\",\n",
    "            template_path=os.path.join(os.path.dirname(webserver_files), \"templates\"),\n",
    "            static_path=os.path.join(os.path.dirname(webserver_files), \"static\"),\n",
    "            xsrf_cookies=False,\n",
    "            autoescape=None,\n",
    "            debug=True\n",
    "            )\n",
    "        tornado.web.Application.__init__(self, handlers, **settings)\n",
    "    def startTornado(self):\n",
    "        print(\"Starting Tornaado\")\n",
    "        http_server = tornado.httpserver.HTTPServer(app, ssl_options=ssl_ctx)\n",
    "        http_server.listen(port)\n",
    "        #tornado.ioloop.IOLoop.current().start()\n",
    "    def stopTornado(self):\n",
    "        print(\"Stopping\")\n",
    "        tornado.ioloop.IOLoop.current().stop()\n",
    "\n",
    "class MainHandler(tornado.web.RequestHandler):\n",
    "    def get(self):\n",
    "        self.render(\"facedetect.html\")\n",
    "        \n",
    "class TestHandler(tornado.web.RequestHandler):\n",
    "    def get(self):\n",
    "        self.render(\"dashboard.html\")\n",
    "        \n",
    "class WebcamHandler(tornado.websocket.WebSocketHandler):\n",
    "    '''\n",
    "    When data is received, append it to our thread image queue.\n",
    "    '''\n",
    "    def open(self):\n",
    "        print('new webcam connection')\n",
    "        logging.info('new webcam connection')\n",
    "        #self.set_nodelay(True)\n",
    "        data = {}\n",
    "        data['name'] = 'empty_message'\n",
    "        self.callback = PeriodicCallback(self.update, 500)\n",
    "        self.callback.start()\n",
    "        self.empty_message = json.dumps(data)\n",
    "        self.t1 = time.time()\n",
    "\n",
    "    def on_message(self, message):\n",
    "        image = Image.open(BytesIO(message))\n",
    "        cv_image = numpy.array(image)\n",
    "        thread_image.appendElement(cv_image)\n",
    "        # Send Empty data back\n",
    "        self.write_message(self.empty_message)\n",
    "        self.t1 = time.time()  \n",
    "\n",
    "\n",
    "    def on_close(self):\n",
    "        logging.info('connection webcam closed')\n",
    "        print(\"Connection webcam closed\")\n",
    "        self.callback.stop()\n",
    "    def update(self):\n",
    "        # If we haven't heard back, send a wakeup message.\n",
    "        elapsedTime = time.time() - self.t1\n",
    "        if elapsedTime > 5:\n",
    "            self.write_message(self.empty_message)\n",
    "        \n",
    "        \n",
    "class CNNHandler(tornado.websocket.WebSocketHandler):\n",
    "    '''\n",
    "    When data is received, append it to our thread image queue.\n",
    "    '''\n",
    "    def open(self):\n",
    "        print('new ccn connection')\n",
    "        logging.info('new CNN connection')\n",
    "        self.image_np = np.ones(shape=(6,6,3))\n",
    "        self.next_message = True\n",
    "        self.t1 = time.time()\n",
    "        self.callback = PeriodicCallback(self.update, 200)\n",
    "        self.callback.start()\n",
    "\n",
    "    def on_message(self, message):\n",
    "        self.next_message = True\n",
    "    def update(self):\n",
    "        elapsedTime = time.time() - self.t1\n",
    "        if self.next_message or (elapsedTime > 2):\n",
    "            image_np = nnDraw.showNeuralNetVisualization()*255.0\n",
    "            image_np = image_np.astype('uint8')\n",
    "            data = Image.fromarray(image_np)\n",
    "            fp = BytesIO()\n",
    "            data.save(fp, 'JPEG')\n",
    "            data = base64.b64encode(fp.getvalue())\n",
    "            data = \"data:image/png;base64,\" + data.decode('utf-8')\n",
    "            self.write_message(json.dumps({\n",
    "                \"img\": data,\n",
    "                \"desc\": \"img_description\",\n",
    "            }))\n",
    "            self.next_message = False\n",
    "            self.t1 = time.time()\n",
    "        \n",
    "\n",
    "\n",
    "    def on_close(self):\n",
    "        logging.info('connection CNN closed')\n",
    "        self.callback.stop()\n",
    "        print(\"Connection CNN closed\")\n",
    "\n",
    "class MLResultHandler (tornado.websocket.WebSocketHandler):\n",
    "    '''\n",
    "    When data is received, append it to our thread image queue.\n",
    "    '''\n",
    "    def open(self):\n",
    "        logging.info('new ml result connection')\n",
    "        self.callback = PeriodicCallback(self.update, 500)\n",
    "        self.callback.start()\n",
    "        self.previous_data = []\n",
    "        self.image_height = 0\n",
    "        self.image_width = 0\n",
    "    def on_message(self, message):\n",
    "        if self.image_height == 0:\n",
    "            data = json.loads(message)\n",
    "            try:\n",
    "                self.image_height = int(data['image_properties']['height'])\n",
    "                self.image_width = int(data['image_properties']['width'])\n",
    "                print(\"received\" + \" height: \" + str(self.image_height) + \" width: \" + str(self.image_width))\n",
    "            except:\n",
    "                print(\"nope\")\n",
    "\n",
    "    def create_thread_data(self,thread_data):\n",
    "        all_data = []\n",
    "        current_3d_model = \"default\"\n",
    "        for thread_ in thread_data.thread_list:\n",
    "            h = self.image_height; w = self.image_width;\n",
    "            data = {}\n",
    "            data['type'] = 'thread_data'\n",
    "            data['name'] = thread_.name\n",
    "            if 'thread_frm' in thread_.name:\n",
    "                data,face_data = self.create_face_data(thread_)\n",
    "                all_data.append(data)\n",
    "                all_data.append(face_data)\n",
    "                continue\n",
    "            data['bbs'] = self.fix_bb_coords(thread_.output_data.bbs.copy(),\n",
    "                                        h,w)\n",
    "            data['scores'] = thread_.output_data.scores.tolist()\n",
    "            class_names = []\n",
    "            for c in thread_.output_data.classes:\n",
    "                class_names.append(thread_.output_data.category_index.get(c)['name'])\n",
    "            data['classes'] = class_names\n",
    "            unique_labels = objCounting.countFromList(class_names)\n",
    "            data['unique_labels'] = unique_labels\n",
    "            all_data.append(data)\n",
    "            # Remove the \"Count in front\"\n",
    "            labels = [\" \".join(str(x) for x in label.split(' ')[1:]) for label in unique_labels]\n",
    "            # Check the existence of specific labels for displaying a 3D model\n",
    "            if 'machgun-grip' in labels \\\n",
    "                or 'machine-guns' in labels \\\n",
    "                or 'machgun-barrel' in labels \\\n",
    "                or 'machgun-magazine' in labels \\\n",
    "                or 'rifle-barrel' in labels \\\n",
    "                or 'rifle-cartridge' in labels \\\n",
    "                or 'buttstock' in labels \\\n",
    "                or 'rifle' in labels:\n",
    "                current_3d_model = 'machine_gun'\n",
    "            elif 'gun-barrel' in labels \\\n",
    "                 or 'trigger' in labels \\\n",
    "                 or 'handguns' in labels \\\n",
    "                 or 'grip' in labels:\n",
    "                current_3d_model = 'handgun'\n",
    "\n",
    "            elif 'cell phone' in labels:\n",
    "                current_3d_model = 'mobile'\n",
    "        all_data.append({\n",
    "            \"type\":\"model_display\", \"name\":current_3d_model\n",
    "        })\n",
    "\n",
    "        return all_data\n",
    "    def create_face_data(self,thread_):\n",
    "        # Make sure this is the face thread.\n",
    "        h = self.image_height; w = self.image_width;\n",
    "        data = {}\n",
    "        face_data = {}\n",
    "        face_data[\"type\"] = \"face_display\"\n",
    "        data['type'] = 'thread_data'\n",
    "        data['name'] = thread_.name\n",
    "        output_data = thread_.output_data\n",
    "        recog_trk_ids = list(output_data.recognition_data.output_data.tracker_ids)\n",
    "        persons = list(output_data.recognition_data.output_data.persons)\n",
    "        scores = list(output_data.recognition_data.output_data.scores)\n",
    "        bbs = list(output_data.detection_data.bbs)\n",
    "        detect_trk_ids = list(output_data.detection_data.tracker_ids)\n",
    "        output_persons = []\n",
    "        for bb, detector_trk_id in zip(bbs,\n",
    "                                       detect_trk_ids):\n",
    "            try:\n",
    "                indx = recog_trk_ids.index(detector_trk_id)\n",
    "                output_persons.append(persons[indx])\n",
    "            except:\n",
    "                output_persons.append(output_data.recognition_data.EMPTY_ELEMENT)\n",
    "\n",
    "        data['bbs'] = self.fix_bb_coords(bbs.copy(),\n",
    "                                h,w)\n",
    "        data['scores'] = scores\n",
    "        output_persons = [x.split(':')[-1] for x in output_persons]\n",
    "        data['classes'] = output_persons\n",
    "        output_persons = list(set(output_persons))\n",
    "        if len(output_persons) > 0:\n",
    "            if 'Alex' in persons:\n",
    "                 current_face_model = 'lex'\n",
    "            elif 'Brent-Pass' in persons:\n",
    "                 current_face_model = 'brent'\n",
    "            elif 'Carl-freer' in persons:\n",
    "                 current_face_model = 'carl'\n",
    "            elif 'Haris' in persons:\n",
    "                 current_face_model = 'haris'\n",
    "            elif 'Jan' in persons:\n",
    "                 current_face_model = 'jan'\n",
    "            elif 'Lucie-parker' in persons:\n",
    "                 current_face_model = 'lucie'\n",
    "            elif 'omar' in persons:\n",
    "                 current_face_model = 'omar'\n",
    "            elif 'phanikumar' in persons:\n",
    "                 current_face_model = 'phani'\n",
    "            else:\n",
    "                 current_face_model = 'mask'\n",
    "            face_data['name'] = current_face_model\n",
    "        else:\n",
    "            face_data['name'] = 'mask'\n",
    "        return data,face_data\n",
    "        \n",
    "    def update(self):\n",
    "        # First we need to concatenate the output data\n",
    "        all_data = self.create_thread_data(thread_data)\n",
    "\n",
    "        # Add the face data. TODO: Pass in the face data!\n",
    "        #data = json.dumps(self.create_face_and_model_data(thread_frm.output_data))\n",
    "        #all_data.append(data)\n",
    "        # Prevent sending duplicate data.\n",
    "        if all_data != self.previous_data:\n",
    "            self.write_message(json.dumps(all_data))\n",
    "        self.previous_data = all_data\n",
    "\n",
    "    def fix_bb_coords(self,bbs,h,w):\n",
    "        for indx, bb in enumerate(bbs):\n",
    "            bbs[indx][0] = int(bbs[indx][0]*h)\n",
    "            bbs[indx][1] = int(bbs[indx][1]*w)\n",
    "            bbs[indx][2] = int(bbs[indx][2]*h)\n",
    "            bbs[indx][3] = int(bbs[indx][3]*w)  \n",
    "            \n",
    "            bbs[indx][0] = max(min(bbs[indx][0],h),0)\n",
    "            bbs[indx][2] = max(min(bbs[indx][2],h),0)\n",
    "            bbs[indx][1] = max(min(bbs[indx][1],w),0)\n",
    "            bbs[indx][3] = max(min(bbs[indx][3],w),0)\n",
    "        try:     \n",
    "            return bbs.tolist()\n",
    "        except:\n",
    "            return bbs\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    def on_close(self):\n",
    "        logging.info('connection ml closed')\n",
    "        self.callback.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_gsm_1.continue_predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Application()\n",
    "ssl_ctx = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n",
    "ssl_ctx.load_cert_chain(webserver_files + \"ssl/domain.crt\",\n",
    "                       webserver_files + \"ssl/domain.key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tornado.access:404 GET /favicon.ico (94.204.13.240) 172.28ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection CNN closed\n",
      "Connection webcam closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection CNN closed\n",
      "Connection webcam closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection CNN closed\n",
      "Connection webcam closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection CNN closed\n",
      "Connection webcam closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection webcam closed\n",
      "Connection CNN closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection CNN closed\n",
      "Connection webcam closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection CNN closed\n",
      "Connection webcam closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.application:Uncaught exception GET /webcam (94.204.13.240)\n",
      "HTTPServerRequest(protocol='https', host='watstock.omarabid4.com:8888', method='GET', uri='/webcam', version='HTTP/1.1', remote_ip='94.204.13.240')\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/websocket.py\", line 867, in write_message\n",
      "    fut = self._write_frame(True, opcode, message, flags=flags)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/websocket.py\", line 846, in _write_frame\n",
      "    return self.stream.write(frame)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/iostream.py\", line 570, in write\n",
      "    self._check_closed()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/iostream.py\", line 1112, in _check_closed\n",
      "    raise StreamClosedError(real_error=self.error)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/websocket.py\", line 546, in _run_callback\n",
      "    result = callback(*args, **kwargs)\n",
      "  File \"<ipython-input-10-7a6eeb8557de>\", line 57, in on_message\n",
      "    self.write_message(self.empty_message)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/websocket.py\", line 262, in write_message\n",
      "    return self.ws_connection.write_message(message, binary=binary)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/websocket.py\", line 869, in write_message\n",
      "    raise WebSocketClosedError()\n",
      "tornado.websocket.WebSocketClosedError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection webcam closed\n",
      "Connection CNN closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection CNN closed\n",
      "Connection webcam closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection CNN closed\n",
      "Connection webcam closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection webcam closed\n",
      "Connection CNN closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection CNN closed\n",
      "Connection webcam closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection CNN closed\n",
      "Connection webcam closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection CNN closed\n",
      "Connection webcam closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection webcam closed\n",
      "Connection CNN closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection CNN closed\n",
      "Connection webcam closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection CNN closed\n",
      "Connection webcam closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection CNN closed\n",
      "Connection webcam closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n",
      "Connection CNN closed\n",
      "Connection webcam closed\n",
      "new webcam connection\n",
      "new ccn connection\n",
      "received height: 357 width: 674\n"
     ]
    }
   ],
   "source": [
    "http_server = tornado.httpserver.HTTPServer(app, ssl_options=ssl_ctx)\n",
    "http_server.listen(port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'id': 1, 'name': 'person'},\n",
       " 2: {'id': 2, 'name': 'bicycle'},\n",
       " 3: {'id': 3, 'name': 'car'},\n",
       " 4: {'id': 4, 'name': 'motorbike'},\n",
       " 5: {'id': 5, 'name': 'aeroplane'},\n",
       " 6: {'id': 6, 'name': 'bus'},\n",
       " 7: {'id': 7, 'name': 'train'},\n",
       " 8: {'id': 8, 'name': 'truck'},\n",
       " 9: {'id': 9, 'name': 'boat'},\n",
       " 10: {'id': 10, 'name': 'traffic light'},\n",
       " 11: {'id': 11, 'name': 'fire hydrant'},\n",
       " 12: {'id': 12, 'name': 'stop sign'},\n",
       " 13: {'id': 13, 'name': 'parking meter'},\n",
       " 14: {'id': 14, 'name': 'bench'},\n",
       " 15: {'id': 15, 'name': 'bird'},\n",
       " 16: {'id': 16, 'name': 'cat'},\n",
       " 17: {'id': 17, 'name': 'dog'},\n",
       " 18: {'id': 18, 'name': 'horse'},\n",
       " 19: {'id': 19, 'name': 'sheep'},\n",
       " 20: {'id': 20, 'name': 'cow'},\n",
       " 21: {'id': 21, 'name': 'elephant'},\n",
       " 22: {'id': 22, 'name': 'bear'},\n",
       " 23: {'id': 23, 'name': 'zebra'},\n",
       " 24: {'id': 24, 'name': 'giraffe'},\n",
       " 25: {'id': 25, 'name': 'backpack'},\n",
       " 26: {'id': 26, 'name': 'umbrella'},\n",
       " 27: {'id': 27, 'name': 'handbag'},\n",
       " 28: {'id': 28, 'name': 'tie'},\n",
       " 29: {'id': 29, 'name': 'suitcase'},\n",
       " 30: {'id': 30, 'name': 'frisbee'},\n",
       " 31: {'id': 31, 'name': 'skis'},\n",
       " 32: {'id': 32, 'name': 'snowboard'},\n",
       " 33: {'id': 33, 'name': 'sports ball'},\n",
       " 34: {'id': 34, 'name': 'kite'},\n",
       " 35: {'id': 35, 'name': 'baseball bat'},\n",
       " 36: {'id': 36, 'name': 'baseball glove'},\n",
       " 37: {'id': 37, 'name': 'skateboard'},\n",
       " 38: {'id': 38, 'name': 'surfboard'},\n",
       " 39: {'id': 39, 'name': 'tennis racket'},\n",
       " 40: {'id': 40, 'name': 'bottle'},\n",
       " 41: {'id': 41, 'name': 'wine glass'},\n",
       " 42: {'id': 42, 'name': 'cup'},\n",
       " 43: {'id': 43, 'name': 'fork'},\n",
       " 44: {'id': 44, 'name': 'knife'},\n",
       " 45: {'id': 45, 'name': 'spoon'},\n",
       " 46: {'id': 46, 'name': 'bowl'},\n",
       " 47: {'id': 47, 'name': 'banana'},\n",
       " 48: {'id': 48, 'name': 'apple'},\n",
       " 49: {'id': 49, 'name': 'sandwich'},\n",
       " 50: {'id': 50, 'name': 'orange'},\n",
       " 51: {'id': 51, 'name': 'broccoli'},\n",
       " 52: {'id': 52, 'name': 'carrot'},\n",
       " 53: {'id': 53, 'name': 'hot dog'},\n",
       " 54: {'id': 54, 'name': 'pizza'},\n",
       " 55: {'id': 55, 'name': 'donut'},\n",
       " 56: {'id': 56, 'name': 'cake'},\n",
       " 57: {'id': 57, 'name': 'chair'},\n",
       " 58: {'id': 58, 'name': 'sofa'},\n",
       " 59: {'id': 59, 'name': 'pottedplant'},\n",
       " 60: {'id': 60, 'name': 'bed'},\n",
       " 61: {'id': 61, 'name': 'diningtable'},\n",
       " 62: {'id': 62, 'name': 'toilet'},\n",
       " 63: {'id': 63, 'name': 'tvmonitor'},\n",
       " 64: {'id': 64, 'name': 'laptop'},\n",
       " 65: {'id': 65, 'name': 'mouse'},\n",
       " 66: {'id': 66, 'name': 'remote'},\n",
       " 67: {'id': 67, 'name': 'keyboard'},\n",
       " 68: {'id': 68, 'name': 'cell phone'},\n",
       " 69: {'id': 69, 'name': 'microwave'},\n",
       " 70: {'id': 70, 'name': 'oven'},\n",
       " 71: {'id': 71, 'name': 'toaster'},\n",
       " 72: {'id': 72, 'name': 'sink'},\n",
       " 73: {'id': 73, 'name': 'refrigerator'},\n",
       " 74: {'id': 74, 'name': 'book'},\n",
       " 75: {'id': 75, 'name': 'clock'},\n",
       " 76: {'id': 76, 'name': 'vase'},\n",
       " 77: {'id': 77, 'name': 'scissors'},\n",
       " 78: {'id': 78, 'name': 'teddy bear'},\n",
       " 79: {'id': 79, 'name': 'hair drier'},\n",
       " 80: {'id': 80, 'name': 'toothbrush'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread_gsm_1.output_data.category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 cell phones', '1 person']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = [\"2 cell phones\", \"1 person\"]\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cell phones', 'person']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for label in unique_labels:\n",
    "    label = label.split(' ')[1:]\n",
    "    label = \" \".join(str(x) for x in label)\n",
    "    labels.append(label)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cell phones', 'person']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection CNN closed\n",
      "Connection webcam closed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cell', 'phones']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = '25 cell phones'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cell phones'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
